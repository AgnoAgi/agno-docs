---
title: AWS Bedrock Claude
---

Use AWS Bedrock to access the Claude models.

## Authentication

Set your `AWS_ACCESS_KEY_ID` `AWS_SECRET_ACCESS_KEY` and environment variables.

<CodeGroup>

```bash Mac
export AWS_ACCESS_KEY_ID=***
export AWS_SECRET_ACCESS_KEY=***
```

```bash Windows
setx AWS_ACCESS_KEY_ID ***
setx AWS_SECRET_ACCESS_KEY ***
```

</CodeGroup>

## Example

Use `OpenAIChat` with your `Agent`:

<CodeGroup>

```python agent.py
"""Run `pip install yfinance` to install dependencies."""

from phi.agent import Agent, RunResponse  # noqa
from phi.model.aws.claude import Claude
from phi.tools.yfinance import YFinanceTools

agent = Agent(
    model=Claude(id="anthropic.claude-3-5-sonnet-20240620-v1:0"),
    tools=[YFinanceTools(stock_price=True)],
    show_tool_calls=True,
    markdown=True,
    debug_mode=True,
)

# Get the response in a variable
# run: RunResponse = agent.run("What is the stock price of NVDA and TSLA")
# print(run.content)

# Print the response in the terminal
agent.print_response("What is the stock price of NVDA and TSLA")

```

</CodeGroup>

## Params

<ResponseField name="name" type="str" default="AwsBedrockAnthropicClaude">
  The name identifier for the Claude agent.
</ResponseField>
<ResponseField
  name="id"
  type="str"
  default="anthropic.claude-3-sonnet-20240229-v1:0"
>
  The specific model ID used for generating responses.
</ResponseField>
<ResponseField name="max_tokens" type="int" default="8192">
  The maximum number of tokens to generate in the response.
</ResponseField>
<ResponseField name="temperature" type="Optional[float]">
  The sampling temperature to use, between 0 and 2. Higher values like 0.8 make
  the output more random, while lower values like 0.2 make it more focused and
  deterministic.
</ResponseField>
<ResponseField name="top_p" type="Optional[float]">
  The nucleus sampling parameter. The model considers the results of the tokens
  with top_p probability mass.
</ResponseField>
<ResponseField name="top_k" type="Optional[int]">
  The number of highest probability vocabulary tokens to keep for
  top-k-filtering.
</ResponseField>
<ResponseField name="stop_sequences" type="Optional[List[str]]">
  A list of sequences where the API will stop generating further tokens.
</ResponseField>
<ResponseField name="anthropic_version" type="str" default="bedrock-2023-05-31">
  The version of the Anthropic API to use.
</ResponseField>
<ResponseField name="request_params" type="Optional[Dict[str, Any]]">
  Additional parameters for the request, provided as a dictionary.
</ResponseField>
<ResponseField name="client_params" type="Optional[Dict[str, Any]]">
  Additional client parameters for initializing the `AwsBedrock` client,
  provided as a dictionary.
</ResponseField>
